% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={Single\_effect},
  pdfauthor={Jungang Zou},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering

\title{Single\_effect}
\author{Jungang Zou}
\date{4/28/2021}

\begin{document}
\maketitle

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# import packages and define some useful mathematical functions}
\NormalTok{knitr}\OperatorTok{::}\NormalTok{opts_chunk}\OperatorTok{$}\KeywordTok{set}\NormalTok{(}\DataTypeTok{echo =} \OtherTok{TRUE}\NormalTok{)}
\KeywordTok{library}\NormalTok{(parallel)}
\KeywordTok{library}\NormalTok{(doParallel)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: foreach
\end{verbatim}

\begin{verbatim}
## Loading required package: iterators
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(foreach)}
\KeywordTok{library}\NormalTok{(}\StringTok{"MCMCpack"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: coda
\end{verbatim}

\begin{verbatim}
## Loading required package: MASS
\end{verbatim}

\begin{verbatim}
## ##
## ## Markov Chain Monte Carlo Package (MCMCpack)
\end{verbatim}

\begin{verbatim}
## ## Copyright (C) 2003-2021 Andrew D. Martin, Kevin M. Quinn, and Jong Hee Park
\end{verbatim}

\begin{verbatim}
## ##
## ## Support provided by the U.S. National Science Foundation
\end{verbatim}

\begin{verbatim}
## ## (Grants SES-0350646 and SES-0350613)
## ##
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sigmoid =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x) }\KeywordTok{return}\NormalTok{(}\DecValTok{1} \OperatorTok{/}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{+}\StringTok{ }\KeywordTok{exp}\NormalTok{(}\OperatorTok{-}\NormalTok{x)))}

\NormalTok{softmax =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x)\{}
\NormalTok{  e_x =}\StringTok{ }\KeywordTok{exp}\NormalTok{(x }\OperatorTok{-}\StringTok{ }\KeywordTok{max}\NormalTok{(x))}
  \KeywordTok{return}\NormalTok{(e_x }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(e_x))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\hypertarget{genetic-association-selection-based-on-bayesian-methods}{%
\subsection{Genetic Association Selection based on Bayesian
Methods}\label{genetic-association-selection-based-on-bayesian-methods}}

Nowadays, statistical genetics is becoming more and more popular. It
uses statistical tools to find the statistical association between
disease(or phenotype) with a set of candidate genes, which provides a
pre-selection tool to Biologists. However, in genetic data, usually a
large amount of genes(genotype data) are provided for each sample, but
only few samples(each stands for an individual) are able to be
exploited. This special biological context can lead to a lot of problems
in statistical models, such as intensive computation, high dimension
curse, non-invertible normal matrix in ordinary least square. On the
other hand, Bayesian statistical method gives another framework to cope
with genetic association problems, which mixes up the information based
on personal belief and data. These kind of models are applied in
statistical genetic problems more and more frequently.

To solve the problems caused by genetic data, a lot of different methods
are proposed. The main ideas of these models are based on the fact that
we only need to identify the most significant genes instead of the whole
genetic dataset. In fact, a series of statistical methods built by
frequentists can be exploited for the same application purpose, such as
shrinkage method(Lasso for example), step-wise regression. These methods
can identify the covariates of the most statistical significance. Also,
in Bayesian framework, variable selection technique or model averaging
technique can be used. Bayesian variable selection methods specify
special prior distributions for parameters in regression, where the
inference based on posterior distributions will show whether this
covariate will be included in models. Among a broad range of priors, a
very useful prior is
\href{https://en.wikipedia.org/wiki/Spike-and-slab_regression}{Spike-Slab
prior}. On the other hand, Bayesian Model Averaging considers
probabilities of covariates subsets separately, instead of the whole
dataset. In this method, datasets are separated into different subsets
by columns, then regression models will be fitted on each subset of
variables. Finally, posterior probability of each model will be
calculated with the evidence of data. Generally speaking, there are
totally \(2^p\) models, \(p\) denotes the number of genes. To reduce the
intensive computation, ``single effect'' model is often specified, which
separates the whole data into only \(p\) different subsets and each
subset contains only one variable(gene). For Bayesian Model Averaging,
we consider the effect of only one gene separately, while the co-effect
of all genes will be applied in Bayesian Variable Selection.

In this notebook, we code 2 algorithms to identify significant genes
associated with phenotypes in R code, based on Bayesian Variable
Selection technique and Bayesian Model Averaging technique respectively.

\hypertarget{single-effect-logistic-regression-based-on-bayesian-model-averaging}{%
\subsubsection{Single Effect Logistic Regression based on Bayesian Model
Averaging}\label{single-effect-logistic-regression-based-on-bayesian-model-averaging}}

In our context of single effect logistic regression model, only one gene
will be included in regression. Formally, we can write down the
likelihood of j-th model:

\$p(y \textbar{} x\^{}j, \beta\_0\^{}j, \beta\_1\^{}j, M\^{}j)=
\prod\_i\textsuperscript{n(sigmoid(x\_i}j * \beta\_1\^{}j +
\beta\_0\textsuperscript{j))}\{y\_i\}(1 - sigmoid(x\_i\^{}j *
\beta\_1\^{}j + \beta\_0\textsuperscript{j))}\{1-y\_i\} \$, where
\(x^j\) is the j-th variable, \(x_i^j\) is j-th variable of i-th sample,
\(M^j\) gives this j-th model.

The process of Single Effect Bayesian Model Averaging(BMA) can be
followed by 5 steps: 1. Specify a prior inclusion probability for each
single effect model \(\pi(M_j),j=1,2...p\) with \(\sum_1^p\pi(M_j) = 1\)
constraint. 2. Specify prior of parameters in each model
\(\pi(\beta_0^j, \beta_1^j | M_j)\), then sample \(\beta_0^j\) and
\(\beta_1^j\) from prior distribution. 3. Calculate likelihood under
model
\(p(y |x^j, M_j ) = \int \int p(y|x^j, \beta_0^j, \beta_1^j, M_j) \pi(\beta_0^j, \beta_1^j | M_j) d\beta_0^jd\beta_1^j\)
by Monte Carlo integrals. 4. Calculate posterior inclusion probability
for each model by Bayes Rule
\(\pi(M_j | y, x^j) = \frac{\pi(M_j) *p(y |x^j, M_j ) }{\sum_1^p\pi(M_j) *p(y |x^j, M_j )}\).
5. Use MCMC or Variation Inference methods to infer posterior
distributions for each pair (\(\beta_0^j\), \(\beta_1^j\)), if needed.

\hypertarget{simple-bma-without-inference}{%
\paragraph{Simple BMA without
Inference}\label{simple-bma-without-inference}}

In most of the scenario of genetic association study, the effect of
parameters for significant genes is not rather important. Instead,
posterior inclusion probability(PIP) is what we concern about. Due to
this convenient situation, the algorithm without inference is typically
rapid, with no loop in the procedure.

In our algorithm, we specify a uniform distribution on user-defined
interval \([lower, higher]\) for \(\beta_0^j\), and user-defined normal
distribution \(Normal(\mu_0, \sigma_0^2)\) for \(\beta_1^j\). The code
of simple non-inference BMA method is as follow:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# calculate log-likelihood for a pair of parameters.}
\NormalTok{log_logistic_likelihood =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(x, y, beta_}\DecValTok{0}\NormalTok{, beta_}\DecValTok{1}\NormalTok{, }\DataTypeTok{tol =} \FloatTok{1e-100}\NormalTok{)\{}
\NormalTok{  lm =}\StringTok{ }\NormalTok{beta_}\DecValTok{0} \OperatorTok{+}\StringTok{ }\NormalTok{beta_}\DecValTok{1} \OperatorTok{*}\StringTok{ }\NormalTok{x}
  \KeywordTok{return}\NormalTok{(}\KeywordTok{sum}\NormalTok{(y }\OperatorTok{*}\StringTok{ }\KeywordTok{log}\NormalTok{(}\KeywordTok{sigmoid}\NormalTok{(lm) }\OperatorTok{+}\StringTok{ }\NormalTok{tol) }\OperatorTok{+}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\NormalTok{y) }\OperatorTok{*}\StringTok{ }\KeywordTok{log}\NormalTok{(}\DecValTok{1} \OperatorTok{-}\StringTok{ }\KeywordTok{sigmoid}\NormalTok{(lm) }\OperatorTok{+}\StringTok{ }\NormalTok{tol)))}
\NormalTok{\}}

\CommentTok{# the main algorithm of Bayesian Model Averaging}
\CommentTok{# Input:}
\CommentTok{# X: a matrix of genotype data. The process of centralization or normalization should be calculated before this algorithm if needed.}
\CommentTok{# Y: a vector of phenotype data, only binary data(0 or 1) is allowed. }
\CommentTok{# prior_ip: prior inclusion probability for each model. The size of vector should be consistent with variables of X. If prior_ip is not normalized(sum to 1), a process of normalization will be done in algorithm.}
\CommentTok{# mu0: a scalar to specify the prior normal mean of beta_1}
\CommentTok{# sigma0: a scalar to specify the prior normal standard deviation of beta_1}
\CommentTok{# lower: a scalar to specify the prior lower bound of uniform distribution for beta_0}
\CommentTok{# higher: a scalar to specify the prior upper bound of uniform distribution for beta_0}
\CommentTok{# sample_size: a scalar to specify the number of samples for parameters to perform Monte Carlo Integral for p(data | M_j)}

\CommentTok{# output:}
\CommentTok{# A vector of posterior inclusion probability for each variable.}

\NormalTok{BMA =}\StringTok{ }\ControlFlowTok{function}\NormalTok{(X, Y, prior_ip, mu0, sigma0, lower, higher, }\DataTypeTok{sample_size =} \DecValTok{10000}\NormalTok{)\{}
  \CommentTok{# preparation}
\NormalTok{  n =}\StringTok{ }\KeywordTok{nrow}\NormalTok{(X)}
\NormalTok{  p =}\StringTok{ }\KeywordTok{ncol}\NormalTok{(X)}
  \ControlFlowTok{if}\NormalTok{(}\KeywordTok{length}\NormalTok{(prior_ip) }\OperatorTok{!=}\StringTok{ }\NormalTok{p)\{}
    \KeywordTok{stop}\NormalTok{(}\StringTok{"number of dimensions of prior inclusion probability and X are not consistent"}\NormalTok{)}
\NormalTok{  \}}
  \ControlFlowTok{if}\NormalTok{(}\KeywordTok{sum}\NormalTok{(prior_ip) }\OperatorTok{!=}\StringTok{ }\DecValTok{1}\NormalTok{)}
\NormalTok{    prior_ip =}\StringTok{ }\NormalTok{prior_ip }\OperatorTok{/}\StringTok{ }\KeywordTok{sum}\NormalTok{(prior_ip)}
  
  \CommentTok{# sample parameters}
\NormalTok{  beta_}\DecValTok{0}\NormalTok{ =}\StringTok{ }\KeywordTok{sapply}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{p, }\ControlFlowTok{function}\NormalTok{(x)\{}\KeywordTok{runif}\NormalTok{(sample_size, lower, higher)\})}
\NormalTok{  beta_}\DecValTok{1}\NormalTok{ =}\StringTok{ }\KeywordTok{sapply}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{p, }\ControlFlowTok{function}\NormalTok{(x)\{}\KeywordTok{rnorm}\NormalTok{(sample_size, mu0, sigma0)\})}
  
  \CommentTok{# calculate log-likelihood condition on only model}
\NormalTok{  logp_likelihood =}\StringTok{ }\KeywordTok{sapply}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{p, }\ControlFlowTok{function}\NormalTok{(j)\{}
    \ControlFlowTok{if}\NormalTok{ (p }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{)\{}
\NormalTok{      beta_}\DecValTok{0}\NormalTok{_j =}\StringTok{ }\NormalTok{beta_}\DecValTok{0}
\NormalTok{      beta_}\DecValTok{1}\NormalTok{_j =}\StringTok{ }\NormalTok{beta_}\DecValTok{1}
\NormalTok{      x_j =}\StringTok{ }\NormalTok{X}
\NormalTok{    \}}\ControlFlowTok{else}\NormalTok{\{}
\NormalTok{      beta_}\DecValTok{0}\NormalTok{_j =}\StringTok{ }\NormalTok{beta_}\DecValTok{0}\NormalTok{[, j]}
\NormalTok{      beta_}\DecValTok{1}\NormalTok{_j =}\StringTok{ }\NormalTok{beta_}\DecValTok{1}\NormalTok{[, j]}
\NormalTok{      x_j =}\StringTok{ }\NormalTok{X[, j]}
\NormalTok{    \}}
\NormalTok{    log_likelihood_j =}\StringTok{ }\KeywordTok{log}\NormalTok{(}\KeywordTok{mean}\NormalTok{(}\KeywordTok{exp}\NormalTok{(}\KeywordTok{sapply}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\NormalTok{sample_size, }\ControlFlowTok{function}\NormalTok{(i)\{}
      \KeywordTok{log_logistic_likelihood}\NormalTok{(x_j, Y, beta_}\DecValTok{0}\NormalTok{_j[i], beta_}\DecValTok{1}\NormalTok{_j[i])}
\NormalTok{    \}))))}
\NormalTok{    log_likelihood_j}
\NormalTok{  \})}
  
  \CommentTok{# calculate PIP}
\NormalTok{  logp_prior_ip =}\StringTok{ }\KeywordTok{log}\NormalTok{(prior_ip)}
\NormalTok{  posterior_ip =}\StringTok{ }\KeywordTok{softmax}\NormalTok{(logp_prior_ip }\OperatorTok{+}\StringTok{ }\NormalTok{logp_likelihood)}
  \KeywordTok{return}\NormalTok{(posterior_ip)}
\NormalTok{\}}



\CommentTok{# simulate}
\NormalTok{n =}\StringTok{ }\DecValTok{100}
\NormalTok{mu0 =}\StringTok{ }\DecValTok{0}
\NormalTok{sigma0 =}\StringTok{ }\DecValTok{1}
\NormalTok{lower =}\StringTok{ }\DecValTok{-10}
\NormalTok{higher =}\StringTok{ }\DecValTok{10}
\NormalTok{X =}\StringTok{ }\KeywordTok{cbind}\NormalTok{(}\KeywordTok{rnorm}\NormalTok{(n), }\KeywordTok{rnorm}\NormalTok{(n, }\DecValTok{1}\NormalTok{), }\KeywordTok{rnorm}\NormalTok{(n, }\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{))}
\NormalTok{b =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{,}\OperatorTok{-}\DecValTok{2}\NormalTok{)}
\NormalTok{Y =}\StringTok{ }\KeywordTok{rbinom}\NormalTok{(n, }\DecValTok{1}\NormalTok{, }\KeywordTok{sigmoid}\NormalTok{(X }\OperatorTok{%*%}\StringTok{ }\NormalTok{b }\OperatorTok{+}\StringTok{ }\DecValTok{2}\NormalTok{))}

\KeywordTok{BMA}\NormalTok{(X, Y, }\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\OperatorTok{/}\KeywordTok{ncol}\NormalTok{(X), }\KeywordTok{ncol}\NormalTok{(X)), mu0, sigma0, lower, higher)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.424108e-12 5.201328e-10 1.000000e+00
\end{verbatim}

\hypertarget{the-rest-of-notebook-has-not-been-completed-yet-and-will-be-done-a-few-days-later.}{%
\section{The rest of notebook has not been completed yet and will be
done a few days
later.}\label{the-rest-of-notebook-has-not-been-completed-yet-and-will-be-done-a-few-days-later.}}

\end{document}
